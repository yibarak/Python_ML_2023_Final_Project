{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913de0e2-c720-4354-95ca-b845919a1133",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858fabf7-b583-4bea-9807-6d834eb37ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, TextVectorization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical, plot_model, pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89eaf9d-46ab-4cca-9bf8-e143922fddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43285691-9b2b-4e82-b92e-250bc3c00a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv(\"wine_reviews.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9cb6f9-6a83-4fb2-b798-1303202ed02e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>year</th>\n",
       "      <th>price_log</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>couotry_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling (Lake Michigan Shore)</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child Block Pinot Noir (Willamette Valley)</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  \\\n",
       "0     Italy   \n",
       "1  Portugal   \n",
       "2        US   \n",
       "3        US   \n",
       "4        US   \n",
       "\n",
       "                                                                                                                                                                                                                                                 description  \\\n",
       "0                                                                               Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.   \n",
       "1                        This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.   \n",
       "2                                                                 Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.   \n",
       "3                                                    Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.   \n",
       "4  Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco    87.0   19.0  Sicily & Sardinia   \n",
       "1                            Avidagos    87.0   15.0              Douro   \n",
       "2                             Unknown    87.0   14.0             Oregon   \n",
       "3                Reserve Late Harvest    87.0   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block    87.0   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna            Unknown       Kerin O’Keefe   \n",
       "1              Unknown            Unknown          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore            Unknown  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "                                                                                 title  \\\n",
       "0                                                    Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1                                        Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2                                        Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                  St. Julian 2013 Reserve Late Harvest Riesling (Lake Michigan Shore)   \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child Block Pinot Noir (Willamette Valley)   \n",
       "\n",
       "          variety               winery  year  price_log  desc_len  \\\n",
       "0     White Blend              Nicosia  2013   2.944439        24   \n",
       "1  Portuguese Red  Quinta dos Avidagos  2011   2.708050        38   \n",
       "2      Pinot Gris            Rainstorm  2013   2.639057        28   \n",
       "3        Riesling           St. Julian  2013   2.564949        33   \n",
       "4      Pinot Noir         Sweet Cheeks  2012   4.174387        41   \n",
       "\n",
       "   couotry_codes  \n",
       "0             22  \n",
       "1             31  \n",
       "2             40  \n",
       "3             40  \n",
       "4             40  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e136e44b-0823-4553-b852-cdbf9dc14277",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_full = pd.read_csv(\"results_df.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da734dcd-521c-4a73-8121-0138ef233921",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20d1954-479f-4921-9ddd-b6ac5e0ae9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "      <th>price_log</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>year</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "      <td>2013</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>Douro</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>2011</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.</td>\n",
       "      <td>US</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>2013</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.</td>\n",
       "      <td>US</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>2013</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.</td>\n",
       "      <td>US</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>2012</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 description  \\\n",
       "0                                                                               Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.   \n",
       "1                        This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.   \n",
       "2                                                                 Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.   \n",
       "3                                                    Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.   \n",
       "4  Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.   \n",
       "\n",
       "    country  price_log           province             region_1  \\\n",
       "0     Italy   2.944439  Sicily & Sardinia                 Etna   \n",
       "1  Portugal   2.708050              Douro              Unknown   \n",
       "2        US   2.639057             Oregon    Willamette Valley   \n",
       "3        US   2.564949           Michigan  Lake Michigan Shore   \n",
       "4        US   4.174387             Oregon    Willamette Valley   \n",
       "\n",
       "          variety               winery  year  points  \n",
       "0     White Blend              Nicosia  2013    87.0  \n",
       "1  Portuguese Red  Quinta dos Avidagos  2011    87.0  \n",
       "2      Pinot Gris            Rainstorm  2013    87.0  \n",
       "3        Riesling           St. Julian  2013    87.0  \n",
       "4      Pinot Noir         Sweet Cheeks  2012    87.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr_work = wine_reviews[['description','country','price_log','province','region_1','variety','winery','year','points']]\n",
    "wr_work.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f31fa21-d37b-49e2-8dfa-a389a9b68bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['country', 'province', 'region_1', 'variety', 'winery', 'year']\n",
    "numerical_cols = ['price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518b326e-7ec0-4cfe-afc4-357d4da03fed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\197381738.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work.country = pd.Categorical(wr_work.country).codes\n",
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\197381738.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work.province = pd.Categorical(wr_work.province).codes\n",
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\197381738.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work.region_1 = pd.Categorical(wr_work.region_1).codes\n",
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\197381738.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work.variety = pd.Categorical(wr_work.variety).codes\n",
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\197381738.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work.winery = pd.Categorical(wr_work.winery).codes\n",
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\197381738.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work.year = pd.Categorical(wr_work.year).codes\n"
     ]
    }
   ],
   "source": [
    "wr_work.country = pd.Categorical(wr_work.country).codes\n",
    "wr_work.province = pd.Categorical(wr_work.province).codes\n",
    "wr_work.region_1 = pd.Categorical(wr_work.region_1).codes\n",
    "wr_work.variety = pd.Categorical(wr_work.variety).codes\n",
    "wr_work.winery = pd.Categorical(wr_work.winery).codes\n",
    "wr_work.year = pd.Categorical(wr_work.year).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa857b33-9d3e-4a0d-bad3-70f02a946cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yibar\\AppData\\Local\\Temp\\ipykernel_12588\\1214118844.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wr_work[['price_log', 'points']] = minmax.fit_transform(wr_work[['price_log', 'points']])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "      <th>price_log</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>year</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.</td>\n",
       "      <td>22</td>\n",
       "      <td>0.232026</td>\n",
       "      <td>331</td>\n",
       "      <td>424</td>\n",
       "      <td>691</td>\n",
       "      <td>11608</td>\n",
       "      <td>53</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.</td>\n",
       "      <td>31</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>108</td>\n",
       "      <td>1094</td>\n",
       "      <td>450</td>\n",
       "      <td>12956</td>\n",
       "      <td>51</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.</td>\n",
       "      <td>40</td>\n",
       "      <td>0.186551</td>\n",
       "      <td>268</td>\n",
       "      <td>1218</td>\n",
       "      <td>436</td>\n",
       "      <td>13018</td>\n",
       "      <td>53</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.</td>\n",
       "      <td>40</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>218</td>\n",
       "      <td>549</td>\n",
       "      <td>479</td>\n",
       "      <td>14390</td>\n",
       "      <td>53</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.</td>\n",
       "      <td>40</td>\n",
       "      <td>0.415180</td>\n",
       "      <td>268</td>\n",
       "      <td>1218</td>\n",
       "      <td>440</td>\n",
       "      <td>14621</td>\n",
       "      <td>52</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 description  \\\n",
       "0                                                                               Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.   \n",
       "1                        This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.   \n",
       "2                                                                 Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.   \n",
       "3                                                    Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of honey-drizzled guava and mango giving way to a slightly astringent, semidry finish.   \n",
       "4  Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal characteristics. Nonetheless, if you think of it as a pleasantly unfussy country wine, it's a good companion to a hearty winter stew.   \n",
       "\n",
       "   country  price_log  province  region_1  variety  winery  year  points  \n",
       "0       22   0.232026       331       424      691   11608    53    0.35  \n",
       "1       31   0.196825       108      1094      450   12956    51    0.35  \n",
       "2       40   0.186551       268      1218      436   13018    53    0.35  \n",
       "3       40   0.175516       218       549      479   14390    53    0.35  \n",
       "4       40   0.415180       268      1218      440   14621    52    0.35  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = MinMaxScaler()\n",
    "wr_work[['price_log', 'points']] = minmax.fit_transform(wr_work[['price_log', 'points']])\n",
    "wr_work.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b574e8-95df-45a0-a42d-ec34159bbd52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Embedding Text without pre-train embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f2915a-6207-49cc-bf62-5630d460cc15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_desc_len = max(wine_reviews.desc_len)\n",
    "max_desc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f739082-abfb-4ece-a511-c0dc6ed7caff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_1000 = Tokenizer(num_words=1000)\n",
    "tokenizer_1000.fit_on_texts(wr_work.description)\n",
    "desc_1000 = tokenizer_1000.texts_to_sequences(wr_work.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87551330-7ea0-476f-8a15-812bca0470d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 141, 357,  18],\n",
       "       [  0,   0,   0, ..., 438,  20, 419],\n",
       "       [  0,   0,   0, ..., 807, 727, 480],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  23,  20, 312],\n",
       "       [  0,   0,   0, ...,  23,  20, 588],\n",
       "       [  0,   0,   0, ..., 266,  23,  45]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_1000_max = pad_sequences(desc_1000, maxlen=max_desc_len)\n",
    "desc_1000_60 = pad_sequences(desc_1000, maxlen=60)\n",
    "desc_1000_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3850738-c355-4736-8578-baf486b662c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_5000 = Tokenizer(num_words=5000)\n",
    "tokenizer_5000.fit_on_texts(wr_work.description)\n",
    "desc_5000 = tokenizer_5000.texts_to_sequences(wr_work.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe2876d-1552-4b87-a90e-336e171960b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 141, 357,  18],\n",
       "       [  0,   0,   0, ..., 438,  20, 419],\n",
       "       [  0,   0,   0, ..., 807, 727, 480],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  23,  20, 312],\n",
       "       [  0,   0,   0, ...,  23,  20, 588],\n",
       "       [  0,   0,   0, ..., 266,  23,  45]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_5000_max = pad_sequences(desc_5000, maxlen=max_desc_len)\n",
    "desc_5000_60 = pad_sequences(desc_5000, maxlen=60)\n",
    "desc_5000_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b74d8c-7756-4ba8-bc38-b796c57e4a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wr_work[categorical_cols + numerical_cols], wr_work.points, \\\n",
    "                                                    test_size = 0.25, shuffle = True, random_state = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7236f6a5-1a6b-476f-a1f0-4d906ba022b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desc_1000_max_train, desc_1000_max_test = train_test_split(desc_1000_max, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "desc_1000_60_train, desc_1000_60_test = train_test_split(desc_1000_60, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "desc_5000_max_train, desc_5000_max_test = train_test_split(desc_5000_max, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "desc_5000_60_train, desc_5000_60_test = train_test_split(desc_5000_60, test_size = 0.25, shuffle = True, random_state = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57247579-ed67-4d8d-bf16-aece6a7480ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "3047/3047 - 3s - loss: 0.0376 - 3s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0387 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0515 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0527 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0241 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0255 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0150 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0170 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0414 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0439 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0086 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0103 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0051 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0077 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0105 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0120 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0066 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0093 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0082 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0111 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0047 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0074 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0084 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0100 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0069 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0091 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "3047/3047 - 4s - loss: 0.0061 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0092 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0057 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0077 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0038 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0072 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0041 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0076 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 5s - loss: 0.0046 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 1s - loss: 0.0077 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "3047/3047 - 5s - loss: 0.0048 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0081 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0062 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0081 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0065 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0077 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0046 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0067 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0049 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0071 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0049 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0072 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0044 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0067 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0042 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0069 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0042 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0068 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0051 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0071 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0044 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0068 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0042 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0067 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0046 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0069 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0040 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0070 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "3047/3047 - 4s - loss: 0.0043 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0070 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0044 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0066 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0042 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0069 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0047 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 2s - loss: 0.0068 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0038 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 2s - loss: 0.0072 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "3047/3047 - 4s - loss: 0.0040 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 2s - loss: 0.0073 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0473 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0483 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0216 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0237 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0223 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0236 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0106 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0122 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0083 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0101 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0056 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 2s - loss: 0.0078 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0119 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0133 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0069 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0085 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0063 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0089 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0044 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0072 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0043 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0071 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0044 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0077 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0050 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0074 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "3047/3047 - 4s - loss: 0.0053 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0077 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0041 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0071 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0042 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0070 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0038 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0072 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0036 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0073 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "3047/3047 - 4s - loss: 0.0046 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0080 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0054 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0076 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0056 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0072 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0049 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0069 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0048 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0069 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0048 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0070 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 4s - loss: 0.0045 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0067 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0042 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0068 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0052 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0074 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 4s - loss: 0.0039 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 2s - loss: 0.0070 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 5s - loss: 0.0040 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0068 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 4s - loss: 0.0043 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 1s - loss: 0.0068 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 4s - loss: 0.0044 - 4s/epoch - 1ms/step\n",
      "1016/1016 - 2s - loss: 0.0067 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 13s - loss: 0.0045 - 13s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0067 - 4s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "3047/3047 - 9s - loss: 0.0042 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0070 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 9s - loss: 0.0041 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0068 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 9s - loss: 0.0038 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0070 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 9s - loss: 0.0040 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0069 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 9s - loss: 0.0040 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0072 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "3047/3047 - 10s - loss: 0.0038 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0071 - 3s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "desc_words = [1000, 5000]\n",
    "desc_len = [max_desc_len, 60]\n",
    "dense_activations = ['relu', 'sigmoid']\n",
    "dense_units_1 =  [8, 16, 32, 64, 128]\n",
    "dense_units_2 = [4, 8, 16, 32, 64]\n",
    "model_1_results_df = pd.DataFrame(columns = ['parameters', 'train_MSE', 'test_MSE'])\n",
    "\n",
    "for a in desc_words:\n",
    "    for b in desc_len:\n",
    "        for c in dense_activations:\n",
    "            for d in dense_units_1:\n",
    "                for e in dense_units_2:\n",
    "                    params = {'desc_words' : a, 'desc_len': b, 'activation': c,  'units layer 1': d, 'units layer 2': e}\n",
    "                    if e > d:\n",
    "                        print(f'Passing Parameters: {params}')\n",
    "                        continue  \n",
    "                    \n",
    "                    input_1 = Input(shape=(b,))\n",
    "                    embedding_1 = Embedding(input_dim = a, output_dim=10)(input_1)\n",
    "                    flatten_1 = Flatten()(embedding_1)\n",
    "                    dense_1a = Dense(units = d, activation = c)(flatten_1)\n",
    "                    drop_1 =  Dropout(0.5)(dense_1a)\n",
    "                    dense_1b = Dense(units = e, activation= c)(drop_1)\n",
    "                    output_1 = Dense(units = 1, activation= 'linear')(dense_1b)\n",
    "                    model_1 = Model(inputs=[input_1], outputs=output_1)\n",
    "\n",
    "                    model_1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "                    \n",
    "                    if a == 1000 and b == max_desc_len:\n",
    "                        x_train_1, x_test_1 = desc_1000_max_train, desc_1000_max_test\n",
    "                    elif a == 1000 and b == 60:\n",
    "                        x_train_1, x_test_1 = desc_1000_60_train, desc_1000_60_test\n",
    "                    elif a == 5000 and b == max_desc_len:\n",
    "                        x_train_1, x_test_1 = desc_5000_max_train, desc_5000_max_test\n",
    "                    elif a == 5000 and b == 60:\n",
    "                        x_train_1, x_test_1 = desc_5000_60_train, desc_5000_60_test\n",
    "                        \n",
    "                    print(f'Fitting Model 1, Parameters: {params}')\n",
    "                    model_1.fit(x_train_1, y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=10,\n",
    "                                callbacks=EarlyStopping(monitor='val_loss', patience=3),\n",
    "                                workers = 8,\n",
    "                                verbose = 0,\n",
    "                        validation_data=(x_test_1, y_test))\n",
    "                    print(f'Evaluating Model 1, Parameters: {params}')\n",
    "                    train_MSE = model_1.evaluate(x_train_1, y_train, verbose = 2)\n",
    "                    test_MSE = model_1.evaluate(x_test_1, y_test, verbose = 2)\n",
    "            \n",
    "                    model_1_results_df.loc[len(model_1_results_df.index)] = ([params, train_MSE, test_MSE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b03f5c69-ee1d-4a27-9e37-af482ed7e397",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.006671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.006674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.006691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.006697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.006705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.006736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.006773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.006798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.006803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.006811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.006819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.006830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.006858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.006861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.006865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.006895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.006898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.006968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.006988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.006988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.006994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.006996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.007041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.007072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.007078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.007081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    parameters  \\\n",
       "109   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "144    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "105    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "145    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "138     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "100    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "97     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}   \n",
       "104    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "139     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "142     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "111  {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "147    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "102   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "143     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "106   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "101    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "136     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}   \n",
       "110   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "135     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}   \n",
       "149   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "107   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "129       {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "137    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}   \n",
       "108   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}   \n",
       "146    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}   \n",
       "141    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "148    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "128       {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "151   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}   \n",
       "124        {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "\n",
       "     train_MSE  test_MSE  \n",
       "109   0.004404  0.006614  \n",
       "144   0.004444  0.006671  \n",
       "105   0.004178  0.006674  \n",
       "145   0.004514  0.006691  \n",
       "138   0.004480  0.006697  \n",
       "100   0.004406  0.006705  \n",
       "97    0.004639  0.006736  \n",
       "104   0.004432  0.006773  \n",
       "139   0.004229  0.006798  \n",
       "142   0.004031  0.006803  \n",
       "111   0.004704  0.006811  \n",
       "147   0.004122  0.006819  \n",
       "102   0.004173  0.006830  \n",
       "143   0.004273  0.006837  \n",
       "106   0.004569  0.006858  \n",
       "101   0.004229  0.006861  \n",
       "136   0.004780  0.006865  \n",
       "110   0.004184  0.006866  \n",
       "135   0.004869  0.006895  \n",
       "149   0.003965  0.006898  \n",
       "107   0.004007  0.006968  \n",
       "129   0.004197  0.006988  \n",
       "137   0.004783  0.006988  \n",
       "108   0.004347  0.006993  \n",
       "146   0.004200  0.006994  \n",
       "141   0.003943  0.006996  \n",
       "148   0.003819  0.007041  \n",
       "128   0.004098  0.007072  \n",
       "151   0.003826  0.007078  \n",
       "124   0.004257  0.007081  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results_df.sort_values(by = 'test_MSE', ascending = True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a821dfee-31c6-4526-a92f-1664b2f6f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_results_df.to_csv(\"model_1_results_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5aaa59-6318-4e22-b268-faf110fcdb68",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the next Tests: Keep the sigmoid activation, higher numbers of units layer 1, lower numbers or unit layer 2, and 5000 desc words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8b18b96-1cc4-4543-be34-571981d46788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1_params = model_1_results_df.loc[model_1_results_df.test_MSE == min(model_1_results_df.test_MSE), 'parameters'].values[0]\n",
    "model_1_train_MSE = model_1_results_df.loc[model_1_results_df.test_MSE == min(model_1_results_df.test_MSE), 'train_MSE'].values[0]\n",
    "model_1_test_MSE = model_1_results_df.loc[model_1_results_df.test_MSE == min(model_1_results_df.test_MSE), 'test_MSE'].values[0]\n",
    "\n",
    "results_df_full.loc[len(results_df_full.index)] = ('Embedding without pre-train', ['description'], \\\n",
    "                                                    model_1_params, model_1_train_MSE, model_1_test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16482af1-8ef8-4f54-b115-5e95e382a146",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>variables</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['country mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__n_neighbors': 19}</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.013031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR Lasso (L1)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1e-05}</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR Ridge (L2)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1}</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 1000}</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.012055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NLP Bag of Words + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NLP TFIDF + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['description']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.012018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All variables (NLP Bag of Words) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All variables (NLP TFIDF) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   method  \\\n",
       "0                             simple mean   \n",
       "1                             simple mean   \n",
       "2                                     KNN   \n",
       "3                           LR Lasso (L1)   \n",
       "4                           LR Ridge (L2)   \n",
       "5                           Random Forest   \n",
       "6                   NLP Bag of Words + LR   \n",
       "7                          NLP TFIDF + LR   \n",
       "8                           Random Forest   \n",
       "9   All variables (NLP Bag of Words) + LR   \n",
       "10         All variables (NLP TFIDF) + LR   \n",
       "11            Embedding without pre-train   \n",
       "\n",
       "                                                                                       variables  \\\n",
       "0                                                                                ['mean_points']   \n",
       "1                                                                        ['country mean_points']   \n",
       "2                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "3                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "4                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "5                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "6                                                                                    description   \n",
       "7                                                                                    description   \n",
       "8                                                                                ['description']   \n",
       "9   ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "10  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "11                                                                                 [description]   \n",
       "\n",
       "                                                                                                                                                                parameters  \\\n",
       "0                                                                                                                                                                       {}   \n",
       "1                                                                                                                                                                       {}   \n",
       "2                                                                                                                                           {'regressor__n_neighbors': 19}   \n",
       "3                                                                                                                                              {'regressor__alpha': 1e-05}   \n",
       "4                                                                                                                                                  {'regressor__alpha': 1}   \n",
       "5                                                                                                            {'regressor__max_depth': 32, 'regressor__n_estimators': 1000}   \n",
       "6                                                                                {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}   \n",
       "7                                                                               {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}   \n",
       "8   {'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}   \n",
       "9                                                             {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "10                                                           {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "11                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "0    0.023013  0.023359  \n",
       "1    0.021859  0.022136  \n",
       "2    0.013150  0.013031  \n",
       "3    0.012823  0.012928  \n",
       "4    0.012851  0.012933  \n",
       "5    0.012073  0.012055  \n",
       "6    0.007156  0.007156  \n",
       "7    0.007156  0.007166  \n",
       "8    0.012006  0.012018  \n",
       "9    0.005578  0.005553  \n",
       "10   0.005469  0.005436  \n",
       "11   0.004404  0.006614  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef44c6-0ea5-4b51-b824-d753e6ae65e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Embedding all variables, Text without pre-train embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43df291a-cac5-4f17-8312-937c7005e068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country_input = Input(shape=(1,))\n",
    "country_embedding = Embedding(input_dim=max(wr_work.country)+1, output_dim=10)(country_input)\n",
    "country_flatten = Flatten()(country_embedding)\n",
    "\n",
    "province_input = Input(shape=(1,))\n",
    "province_embedding = Embedding(input_dim=max(wr_work.province)+1, output_dim=3)(province_input)\n",
    "province_flatten = Flatten()(province_embedding)\n",
    "\n",
    "region_1_input = Input(shape=(1,))\n",
    "region_1_embedding = Embedding(input_dim=max(wr_work.region_1)+1, output_dim=2)(region_1_input)\n",
    "region_1_flatten = Flatten()(region_1_embedding)\n",
    "\n",
    "variety_input = Input(shape=(1,))\n",
    "variety_embedding = Embedding(input_dim=max(wr_work.variety)+2, output_dim=2)(variety_input)\n",
    "variety_flatten = Flatten()(variety_embedding)\n",
    "\n",
    "winery_input = Input(shape=(1,))\n",
    "winery_embedding = Embedding(input_dim=max(wr_work.winery)+1, output_dim=1)(winery_input)\n",
    "winery_flatten = Flatten()(winery_embedding)\n",
    "\n",
    "year_input = Input(shape=(1,))\n",
    "year_embedding = Embedding(input_dim=max(wr_work.year)+1, output_dim=10)(year_input)\n",
    "year_flatten = Flatten()(year_embedding)\n",
    "\n",
    "price_input = Input(shape=(1,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1607f984-9a96-4287-a1d7-80a688f47268",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "3047/3047 - 5s - loss: 0.0029 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 5s - loss: 0.0031 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 5s - loss: 0.0026 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0056 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 5s - loss: 0.0024 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 6s - loss: 0.0027 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0051 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "3047/3047 - 5s - loss: 0.0025 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0056 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 5s - loss: 0.0024 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 5s - loss: 0.0020 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 5s - loss: 0.0023 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 5s - loss: 0.0024 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "3047/3047 - 5s - loss: 0.0022 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 6s - loss: 0.0025 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 6s - loss: 0.0023 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0056 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 6s - loss: 0.0024 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0056 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 6s - loss: 0.0022 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 2}\n",
      "3047/3047 - 6s - loss: 0.0023 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0060 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 4}\n",
      "3047/3047 - 6s - loss: 0.0030 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0062 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}\n",
      "3047/3047 - 6s - loss: 0.0026 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}\n",
      "3047/3047 - 6s - loss: 0.0029 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0062 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}\n",
      "3047/3047 - 6s - loss: 0.0025 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "3047/3047 - 5s - loss: 0.0026 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0052 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 5s - loss: 0.0026 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 6s - loss: 0.0024 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 5s - loss: 0.0028 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 5s - loss: 0.0023 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "3047/3047 - 5s - loss: 0.0022 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 5s - loss: 0.0024 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 5s - loss: 0.0024 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 5s - loss: 0.0025 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 5s - loss: 0.0032 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0060 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "3047/3047 - 5s - loss: 0.0021 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0054 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 5s - loss: 0.0036 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0065 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 5s - loss: 0.0023 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0056 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 6s - loss: 0.0024 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0053 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 5s - loss: 0.0020 - 5s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0055 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 2}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 2}\n",
      "3047/3047 - 6s - loss: 0.0023 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0058 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 4}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 4}\n",
      "3047/3047 - 6s - loss: 0.0048 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 3s - loss: 0.0083 - 3s/epoch - 3ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}\n",
      "3047/3047 - 6s - loss: 0.0028 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0060 - 2s/epoch - 2ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}\n",
      "3047/3047 - 7s - loss: 0.0021 - 7s/epoch - 2ms/step\n",
      "1016/1016 - 3s - loss: 0.0054 - 3s/epoch - 3ms/step\n",
      "Fitting Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}\n",
      "Evaluating Model 2, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}\n",
      "3047/3047 - 6s - loss: 0.0023 - 6s/epoch - 2ms/step\n",
      "1016/1016 - 2s - loss: 0.0059 - 2s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "desc_words = [5000]\n",
    "desc_len = [max_desc_len, 60]\n",
    "dense_activations = ['sigmoid']\n",
    "dense_units_1 = [32, 64, 128, 256]\n",
    "dense_units_2 = [2, 4, 8, 16, 32]\n",
    "model_2_results_df = pd.DataFrame(columns = ['parameters', 'train_MSE', 'test_MSE'])\n",
    "\n",
    "for a in desc_words:\n",
    "    for b in desc_len:\n",
    "        for c in dense_activations:\n",
    "            for d in dense_units_1:\n",
    "                for e in dense_units_2:\n",
    "                    params = {'desc_words' : a, 'desc_len': b, 'activation': c,  'units layer 1': d, 'units layer 2': e}\n",
    "\n",
    "                    text_input_2 = Input(shape=(b,))\n",
    "                    text_embedding_2 = Embedding(input_dim = a, output_dim=10)(text_input_2)\n",
    "                    text_flatten_2 = Flatten()(text_embedding_2)\n",
    "                    \n",
    "                    concatenated_2 = Concatenate()([text_flatten_2, country_flatten, province_flatten, region_1_flatten, \\\n",
    "                                                    variety_flatten, winery_flatten, year_flatten, price_input])\n",
    "\n",
    "                    dense_2a = Dense(units = d, activation = c)(concatenated_2)\n",
    "                    drop_2 =  Dropout(0.5)(dense_2a)\n",
    "                    dense_2b = Dense(units = d, activation = c)(drop_2)\n",
    "                    output_2 = Dense(units = 1, activation= 'linear')(dense_2b)\n",
    "                    model_2 = Model(inputs=[text_input_2, country_input, province_input, region_1_input, \\\n",
    "                                            variety_input, winery_input, year_input, price_input], outputs=output_2)\n",
    "\n",
    "\n",
    "                    model_2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "                    if a == 1000 and b == max_desc_len:\n",
    "                        x_train_2, x_test_2 = desc_1000_max_train, desc_1000_max_test\n",
    "                    elif a == 1000 and b == 60:\n",
    "                        x_train_2, x_test_2 = desc_1000_60_train, desc_1000_60_test\n",
    "                    elif a == 5000 and b == max_desc_len:\n",
    "                        x_train_2, x_test_2 = desc_5000_max_train, desc_5000_max_test\n",
    "                    elif a == 5000 and b == 60:\n",
    "                        x_train_2, x_test_2 = desc_5000_60_train, desc_5000_60_test\n",
    "                    \n",
    "                    print(f'Fitting Model 2, Parameters: {params}')\n",
    "                    model_2.fit([x_train_2, x_train.country, x_train.province, x_train.region_1,\\\n",
    "                                 x_train.variety, x_train.winery, x_train.year, x_train[numerical_cols]], y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=10,\n",
    "                                callbacks=EarlyStopping(monitor='val_loss', patience=3),\n",
    "                                workers = 8,\n",
    "                                verbose = 0,\n",
    "                                validation_data=([x_test_2, x_test.country, x_test.province, x_test.region_1,\\\n",
    "                                                  x_test.variety, x_test.winery, x_test.year, x_test[numerical_cols]], y_test))\n",
    "                    print(f'Evaluating Model 2, Parameters: {params}')\n",
    "                    train_MSE = model_2.evaluate([x_train_2, x_train.country, x_train.province, x_train.region_1,\\\n",
    "                                 x_train.variety, x_train.winery, x_train.year, x_train[numerical_cols]], y_train, verbose = 2)\n",
    "                    test_MSE = model_2.evaluate([x_test_2, x_test.country, x_test.province, x_test.region_1,\\\n",
    "                                                  x_test.variety, x_test.winery, x_test.year, x_test[numerical_cols]], y_test, verbose = 2)\n",
    "\n",
    "                    model_2_results_df.loc[len(model_2_results_df.index)] = ([params, train_MSE, test_MSE])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f9a33db-ec7e-4a82-aa66-1e219b7d12f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.005252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.005274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.005287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.005296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.005319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.005344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.005447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.005450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.005461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.005552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.005580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   parameters  \\\n",
       "4    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "20     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}   \n",
       "28    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "26     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "23    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "3    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "1     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "21     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "14  {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "33   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "11   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "24    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "10   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}   \n",
       "9    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "8    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "30    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}   \n",
       "0     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}   \n",
       "19  {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}   \n",
       "27     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "7     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "6     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "25     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "38   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}   \n",
       "17   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}   \n",
       "22     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "34   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "5     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "32    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "12   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "2     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "4    0.002700  0.005142  \n",
       "20   0.002566  0.005204  \n",
       "28   0.002482  0.005252  \n",
       "26   0.002381  0.005253  \n",
       "23   0.002779  0.005254  \n",
       "3    0.002425  0.005274  \n",
       "1    0.003137  0.005287  \n",
       "21   0.002550  0.005296  \n",
       "14   0.002182  0.005303  \n",
       "33   0.002448  0.005319  \n",
       "11   0.002470  0.005322  \n",
       "24   0.002298  0.005330  \n",
       "10   0.002163  0.005342  \n",
       "9    0.002383  0.005344  \n",
       "8    0.002328  0.005348  \n",
       "30   0.002080  0.005359  \n",
       "0    0.002853  0.005382  \n",
       "19   0.002489  0.005401  \n",
       "27   0.002436  0.005405  \n",
       "7    0.001993  0.005410  \n",
       "6    0.002396  0.005415  \n",
       "25   0.002201  0.005435  \n",
       "38   0.002083  0.005442  \n",
       "17   0.002561  0.005447  \n",
       "22   0.002421  0.005450  \n",
       "34   0.001984  0.005461  \n",
       "5    0.002495  0.005552  \n",
       "32   0.002321  0.005575  \n",
       "12   0.002283  0.005580  \n",
       "2    0.002557  0.005584  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results_df.sort_values(by = 'test_MSE', ascending = True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6843eae8-d97f-471f-9866-8f1d3c8442a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2_results_df.to_csv(\"model_2_results_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd7c6ed3-2f6b-4bc1-b549-3ada82a1c69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2_params = model_2_results_df.loc[model_2_results_df.test_MSE == min(model_2_results_df.test_MSE), 'parameters'].values[0]\n",
    "model_2_train_MSE = model_2_results_df.loc[model_2_results_df.test_MSE == min(model_2_results_df.test_MSE), 'train_MSE'].values[0]\n",
    "model_2_test_MSE = model_2_results_df.loc[model_2_results_df.test_MSE == min(model_2_results_df.test_MSE), 'test_MSE'].values[0]\n",
    "\n",
    "results_df_full.loc[len(results_df_full.index)] = ('Embedding without pre-train', categorical_cols + numerical_cols + ['description'], \\\n",
    "                                                    model_2_params, model_2_train_MSE, model_2_test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5a0bd-0cd4-4fc0-a2d9-5044108f40ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>variables</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['country mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__n_neighbors': 19}</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.013031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR Lasso (L1)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1e-05}</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR Ridge (L2)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1}</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 1000}</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.012055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NLP Bag of Words + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NLP TFIDF + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['description']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.012018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All variables (NLP Bag of Words) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All variables (NLP TFIDF) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[country, province, region_1, variety, winery, year, price_log, description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   method  \\\n",
       "0                             simple mean   \n",
       "1                             simple mean   \n",
       "2                                     KNN   \n",
       "3                           LR Lasso (L1)   \n",
       "4                           LR Ridge (L2)   \n",
       "5                           Random Forest   \n",
       "6                   NLP Bag of Words + LR   \n",
       "7                          NLP TFIDF + LR   \n",
       "8                           Random Forest   \n",
       "9   All variables (NLP Bag of Words) + LR   \n",
       "10         All variables (NLP TFIDF) + LR   \n",
       "11            Embedding without pre-train   \n",
       "12            Embedding without pre-train   \n",
       "\n",
       "                                                                                       variables  \\\n",
       "0                                                                                ['mean_points']   \n",
       "1                                                                        ['country mean_points']   \n",
       "2                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "3                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "4                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "5                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "6                                                                                    description   \n",
       "7                                                                                    description   \n",
       "8                                                                                ['description']   \n",
       "9   ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "10  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "11                                                                                 [description]   \n",
       "12                  [country, province, region_1, variety, winery, year, price_log, description]   \n",
       "\n",
       "                                                                                                                                                                parameters  \\\n",
       "0                                                                                                                                                                       {}   \n",
       "1                                                                                                                                                                       {}   \n",
       "2                                                                                                                                           {'regressor__n_neighbors': 19}   \n",
       "3                                                                                                                                              {'regressor__alpha': 1e-05}   \n",
       "4                                                                                                                                                  {'regressor__alpha': 1}   \n",
       "5                                                                                                            {'regressor__max_depth': 32, 'regressor__n_estimators': 1000}   \n",
       "6                                                                                {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}   \n",
       "7                                                                               {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}   \n",
       "8   {'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}   \n",
       "9                                                             {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "10                                                           {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "11                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "12                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "0    0.023013  0.023359  \n",
       "1    0.021859  0.022136  \n",
       "2    0.013150  0.013031  \n",
       "3    0.012823  0.012928  \n",
       "4    0.012851  0.012933  \n",
       "5    0.012073  0.012055  \n",
       "6    0.007156  0.007156  \n",
       "7    0.007156  0.007166  \n",
       "8    0.012006  0.012018  \n",
       "9    0.005578  0.005553  \n",
       "10   0.005469  0.005436  \n",
       "11   0.004404  0.006614  \n",
       "12   0.002700  0.005142  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6732814-a96d-4fbf-85a8-81787de5f812",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Embedding all variables, Text with GloVe pre-train embbedings Trainbale / Not Trainbale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d380bd01-d6bf-4cc9-b687-df9bce0bfb35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5001, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_path = 'C:\\\\Users\\\\yibar\\\\Python_ML_2023\\\\Exercises\\\\Final Project\\\\glove.6B.100d.txt' # Path to the GloVe embedding file\n",
    "glove_embedding_dim = 100\n",
    "\n",
    "description_index = {key: value for key, value in tokenizer_5000.word_index.items() if value <= 5000}\n",
    "\n",
    "glove_embedding_matrix = np.zeros((len(description_index) + 1, glove_embedding_dim))\n",
    "\n",
    "with open(glove_path, 'r', encoding='utf-8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        print(values)\n",
    "        word = values[0]\n",
    "        if word in description_index:\n",
    "            glove_embedding_matrix[description_index[word]] = np.array(values[1:], dtype=np.float32)\n",
    "glove_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "772bb866-60df-4d40-be5f-fd4397b04b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input_3 = Input(shape=(135,))\n",
    "text_embedding_3 = Embedding(input_dim=glove_embedding_matrix.shape[0], output_dim=glove_embedding_dim, weights=[glove_embedding_matrix], trainable=False)(text_input_3)\n",
    "text_flatten_3 = Flatten()(text_embedding_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a7c4cf2e-a5eb-44cd-8d53-4c497e40e2f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_228 (InputLayer)      [(None, 135)]             0         \n",
      "                                                                 \n",
      " embedding_226 (Embedding)   (None, 135, 100)          500100    \n",
      "                                                                 \n",
      " flatten_224 (Flatten)       (None, 13500)             0         \n",
      "                                                                 \n",
      " dense_651 (Dense)           (None, 64)                864064    \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,364,693\n",
      "Trainable params: 864,593\n",
      "Non-trainable params: 500,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "            dense_3a = Dense(units = 64, activation = '')(text_flatten_3)\n",
    "            drop_3 =  Dropout(0.5)(dense_3a)\n",
    "            dense_3b = Dense(units = 8, activation = 'relu')(drop_3)\n",
    "            output_3 = Dense(units = 1, activation= 'linear')(dense_3b)\n",
    "            model_3 = Model(inputs=text_input_3, outputs=output_3)\n",
    "            \n",
    "            model_3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "            \n",
    "            model_3.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8449c6d7-04af-4dba-9471-6331068f68af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3047/3047 [==============================] - 27s 8ms/step - loss: 0.0215 - val_loss: 0.0219\n",
      "Epoch 2/10\n",
      "3047/3047 [==============================] - 23s 8ms/step - loss: 0.0140 - val_loss: 0.0233\n",
      "Epoch 3/10\n",
      "3047/3047 [==============================] - 23s 8ms/step - loss: 0.0135 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "3047/3047 [==============================] - 23s 8ms/step - loss: 0.0130 - val_loss: 0.0179\n",
      "Epoch 5/10\n",
      "3047/3047 [==============================] - 28s 9ms/step - loss: 0.0128 - val_loss: 0.0205\n",
      "Epoch 6/10\n",
      "3047/3047 [==============================] - 23s 8ms/step - loss: 0.0125 - val_loss: 0.0290\n",
      "Epoch 7/10\n",
      "3047/3047 [==============================] - 23s 8ms/step - loss: 0.0123 - val_loss: 0.0210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df61715400>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "            model_3.fit(desc_5000_max_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=10,\n",
    "                        callbacks=EarlyStopping(monitor='val_loss', patience=3),\n",
    "                        workers = 8,\n",
    "                        verbose = 1,\n",
    "                        validation_data=(desc_5000_max_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bb49c4a-a60c-439d-836f-206661318553",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "3047/3047 - 10s - loss: 0.0046 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0080 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 10s - loss: 0.0050 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0085 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 10s - loss: 0.0049 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0081 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 11s - loss: 0.0045 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0078 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 10s - loss: 0.0045 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0077 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "3047/3047 - 11s - loss: 0.0038 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0077 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 12s - loss: 0.0038 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0075 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 12s - loss: 0.0041 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0079 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 12s - loss: 0.0038 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0076 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 11s - loss: 0.0038 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0075 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "3047/3047 - 13s - loss: 0.0055 - 13s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0089 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 14s - loss: 0.0050 - 14s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0082 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 14s - loss: 0.0049 - 14s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0081 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 14s - loss: 0.0035 - 14s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0078 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 14s - loss: 0.0033 - 14s/epoch - 5ms/step\n",
      "1016/1016 - 5s - loss: 0.0075 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "3047/3047 - 9s - loss: 0.0050 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0086 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 9s - loss: 0.0042 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 9s - loss: 0.0045 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 9s - loss: 0.0044 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0078 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 9s - loss: 0.0040 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "3047/3047 - 10s - loss: 0.0037 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0077 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 9s - loss: 0.0039 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0080 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 9s - loss: 0.0037 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0076 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 9s - loss: 0.0038 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0078 - 4s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 10s - loss: 0.0042 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0078 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "3047/3047 - 11s - loss: 0.0035 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0077 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 10s - loss: 0.0047 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0081 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 11s - loss: 0.0044 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0083 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 13s - loss: 0.0035 - 13s/epoch - 4ms/step\n",
      "1016/1016 - 3s - loss: 0.0076 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 11s - loss: 0.0036 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0077 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "3047/3047 - 11s - loss: 0.0047 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0080 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 10s - loss: 0.0042 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0078 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 11s - loss: 0.0040 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0077 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 11s - loss: 0.0041 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0079 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 11s - loss: 0.0041 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0079 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "3047/3047 - 12s - loss: 0.0040 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0078 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 12s - loss: 0.0036 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0078 - 5s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 12s - loss: 0.0047 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0084 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 12s - loss: 0.0049 - 12s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0085 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 11s - loss: 0.0043 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0079 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "3047/3047 - 14s - loss: 0.0034 - 14s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0075 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 13s - loss: 0.0043 - 13s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0080 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 14s - loss: 0.0046 - 14s/epoch - 5ms/step\n",
      "1016/1016 - 5s - loss: 0.0079 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 14s - loss: 0.0038 - 14s/epoch - 4ms/step\n",
      "1016/1016 - 5s - loss: 0.0080 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 14s - loss: 0.0039 - 14s/epoch - 5ms/step\n",
      "1016/1016 - 5s - loss: 0.0079 - 5s/epoch - 5ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}\n",
      "3047/3047 - 9s - loss: 0.0045 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "3047/3047 - 9s - loss: 0.0054 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0087 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "3047/3047 - 9s - loss: 0.0043 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "3047/3047 - 9s - loss: 0.0040 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0078 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "3047/3047 - 9s - loss: 0.0041 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}\n",
      "3047/3047 - 9s - loss: 0.0046 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0082 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "3047/3047 - 9s - loss: 0.0037 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0078 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "3047/3047 - 9s - loss: 0.0042 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "3047/3047 - 9s - loss: 0.0036 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0077 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "3047/3047 - 9s - loss: 0.0037 - 9s/epoch - 3ms/step\n",
      "1016/1016 - 3s - loss: 0.0079 - 3s/epoch - 3ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}\n",
      "3047/3047 - 11s - loss: 0.0048 - 11s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0081 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "3047/3047 - 11s - loss: 0.0049 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0083 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "3047/3047 - 11s - loss: 0.0046 - 11s/epoch - 4ms/step\n",
      "1016/1016 - 4s - loss: 0.0083 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "3047/3047 - 10s - loss: 0.0035 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0075 - 4s/epoch - 4ms/step\n",
      "Fitting Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 3, Parameters: {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "3047/3047 - 10s - loss: 0.0035 - 10s/epoch - 3ms/step\n",
      "1016/1016 - 4s - loss: 0.0077 - 4s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "trainable = [False, True]\n",
    "desc_words = 5000\n",
    "desc_len = [max_desc_len, 60]\n",
    "dense_activations = ['sigmoid']\n",
    "dense_units_1 = [32, 64, 128]\n",
    "dense_units_2 = [2, 4, 8, 16, 32]\n",
    "model_3_results_df = pd.DataFrame(columns = ['parameters', 'train_MSE', 'test_MSE'])\n",
    "\n",
    "for a in trainable:\n",
    "    for b in desc_len:\n",
    "        for c in dense_activations:\n",
    "            for d in dense_units_1:\n",
    "                for e in dense_units_2:\n",
    "                    params = {'desc_words' : desc_words, 'trainable': a , 'desc_len': b, 'activation': c,  'units layer 1': d, 'units layer 2': e}\n",
    "\n",
    "                    text_input_3 = Input(shape=(b,))\n",
    "                    if trainable == True:\n",
    "                        text_embedding_3 = Embedding(input_dim=glove_embedding_matrix.shape[0], output_dim=glove_embedding_dim, weights=[glove_embedding_matrix], trainable=True)(text_input_3)\n",
    "                    else:\n",
    "                        text_embedding_3 = Embedding(input_dim=glove_embedding_matrix.shape[0], output_dim=glove_embedding_dim, weights=[glove_embedding_matrix], trainable=False)(text_input_3)\n",
    "                    text_flatten_3 = Flatten()(text_embedding_3)\n",
    "                    \n",
    "                    concatenated_3 = Concatenate()([text_flatten_3, country_flatten, province_flatten, region_1_flatten, \\\n",
    "                                                    variety_flatten, winery_flatten, year_flatten, price_input])\n",
    "\n",
    "                    dense_3a = Dense(units = d, activation = c)(concatenated_3)\n",
    "                    drop_3 =  Dropout(0.5)(dense_3a)\n",
    "                    dense_3b = Dense(units = d, activation = c)(drop_3)\n",
    "                    output_3 = Dense(units = 1, activation= 'linear')(dense_3b)\n",
    "                    model_3 = Model(inputs=[text_input_3, country_input, province_input, region_1_input, \\\n",
    "                                            variety_input, winery_input, year_input, price_input], outputs=output_3)\n",
    "\n",
    "\n",
    "                    model_3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "                    if b == max_desc_len:\n",
    "                        x_train_3, x_test_3 = desc_5000_max_train, desc_5000_max_test\n",
    "                    elif b == 60:\n",
    "                        x_train_3, x_test_3 = desc_5000_60_train, desc_5000_60_test\n",
    "                    \n",
    "                    print(f'Fitting Model 3, Parameters: {params}')\n",
    "                    model_3.fit([x_train_3, x_train.country, x_train.province, x_train.region_1,\\\n",
    "                                 x_train.variety, x_train.winery, x_train.year, x_train[numerical_cols]], y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=10,\n",
    "                                callbacks=EarlyStopping(monitor='val_loss', patience=3),\n",
    "                                workers = 8,\n",
    "                                verbose = 0,\n",
    "                                validation_data=([x_test_3, x_test.country, x_test.province, x_test.region_1,\\\n",
    "                                                  x_test.variety, x_test.winery, x_test.year, x_test[numerical_cols]], y_test))\n",
    "                    print(f'Evaluating Model 3, Parameters: {params}')\n",
    "                    train_MSE = model_3.evaluate([x_train_3, x_train.country, x_train.province, x_train.region_1,\\\n",
    "                                 x_train.variety, x_train.winery, x_train.year, x_train[numerical_cols]], y_train, verbose = 2)\n",
    "                    test_MSE = model_3.evaluate([x_test_3, x_test.country, x_test.province, x_test.region_1,\\\n",
    "                                                  x_test.variety, x_test.winery, x_test.year, x_test[numerical_cols]], y_test, verbose = 2)\n",
    "\n",
    "                    model_3_results_df.loc[len(model_3_results_df.index)] = ([params, train_MSE, test_MSE])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e4f09408-2ccb-46e4-861e-8e50a151abde",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.007485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.007536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.007539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.007556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.007611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.007627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.007673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.007685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.007708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.007719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.007734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.007740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.007749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.007752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.007767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.007768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.007785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.007809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.007815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.007833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.007842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.007855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       parameters  \\\n",
       "58    {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "14  {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "9    {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "6     {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "40    {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}   \n",
       "28   {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "22     {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "8    {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "53     {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "5     {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "59    {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "29   {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "4    {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "25    {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}   \n",
       "20     {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "32     {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "13  {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "36     {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "31     {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "23    {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "51      {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "35     {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "18    {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "48     {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "24    {'desc_words': 5000, 'trainable': False, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "3    {'desc_words': 5000, 'trainable': False, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "39    {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "54     {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "47      {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "33    {'desc_words': 5000, 'trainable': True, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "58   0.003519  0.007485  \n",
       "14   0.003343  0.007503  \n",
       "9    0.003765  0.007520  \n",
       "6    0.003783  0.007536  \n",
       "40   0.003424  0.007539  \n",
       "28   0.003508  0.007556  \n",
       "22   0.003699  0.007611  \n",
       "8    0.003783  0.007627  \n",
       "53   0.003585  0.007673  \n",
       "5    0.003799  0.007685  \n",
       "59   0.003524  0.007700  \n",
       "29   0.003597  0.007708  \n",
       "4    0.004537  0.007719  \n",
       "25   0.003524  0.007734  \n",
       "20   0.003732  0.007740  \n",
       "32   0.004019  0.007749  \n",
       "13   0.003454  0.007752  \n",
       "36   0.003569  0.007767  \n",
       "31   0.004188  0.007768  \n",
       "23   0.003816  0.007785  \n",
       "51   0.003650  0.007809  \n",
       "35   0.004050  0.007812  \n",
       "18   0.004374  0.007815  \n",
       "48   0.004028  0.007833  \n",
       "24   0.004152  0.007842  \n",
       "3    0.004483  0.007847  \n",
       "39   0.004335  0.007851  \n",
       "54   0.003679  0.007851  \n",
       "47   0.004301  0.007851  \n",
       "33   0.004133  0.007855  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results_df.sort_values(by = 'test_MSE', ascending = True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91e54009-cdd6-471a-84b7-6d9fc42adea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_3_results_df.to_csv(\"model_3_results_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a250a086-a702-4110-8016-356448e606ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_3_params = model_3_results_df.loc[model_3_results_df.test_MSE == min(model_3_results_df.test_MSE), 'parameters'].values[0]\n",
    "model_3_train_MSE = model_3_results_df.loc[model_3_results_df.test_MSE == min(model_3_results_df.test_MSE), 'train_MSE'].values[0]\n",
    "model_3_test_MSE = model_3_results_df.loc[model_3_results_df.test_MSE == min(model_3_results_df.test_MSE), 'test_MSE'].values[0]\n",
    "\n",
    "results_df_full.loc[len(results_df_full.index)] = ('Embedding with GloVe pre-train embbedings', categorical_cols + numerical_cols + ['description'], \\\n",
    "                                                    model_3_params, model_3_train_MSE, model_3_test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9ddd89f1-90ad-4c07-a094-192c78ce07d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>variables</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['country mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__n_neighbors': 19}</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.013031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR Lasso (L1)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1e-05}</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR Ridge (L2)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1}</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 1000}</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.012055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NLP Bag of Words + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NLP TFIDF + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['description']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.012018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All variables (NLP Bag of Words) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All variables (NLP TFIDF) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[country, province, region_1, variety, winery, year, price_log, description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Embedding with GloVe pre-train embbedings</td>\n",
       "      <td>[country, province, region_1, variety, winery, year, price_log, description]</td>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.007485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       method  \\\n",
       "0                                 simple mean   \n",
       "1                                 simple mean   \n",
       "2                                         KNN   \n",
       "3                               LR Lasso (L1)   \n",
       "4                               LR Ridge (L2)   \n",
       "5                               Random Forest   \n",
       "6                       NLP Bag of Words + LR   \n",
       "7                              NLP TFIDF + LR   \n",
       "8                               Random Forest   \n",
       "9       All variables (NLP Bag of Words) + LR   \n",
       "10             All variables (NLP TFIDF) + LR   \n",
       "11                Embedding without pre-train   \n",
       "12                Embedding without pre-train   \n",
       "13  Embedding with GloVe pre-train embbedings   \n",
       "\n",
       "                                                                                       variables  \\\n",
       "0                                                                                ['mean_points']   \n",
       "1                                                                        ['country mean_points']   \n",
       "2                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "3                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "4                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "5                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "6                                                                                    description   \n",
       "7                                                                                    description   \n",
       "8                                                                                ['description']   \n",
       "9   ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "10  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "11                                                                                 [description]   \n",
       "12                  [country, province, region_1, variety, winery, year, price_log, description]   \n",
       "13                  [country, province, region_1, variety, winery, year, price_log, description]   \n",
       "\n",
       "                                                                                                                                                                parameters  \\\n",
       "0                                                                                                                                                                       {}   \n",
       "1                                                                                                                                                                       {}   \n",
       "2                                                                                                                                           {'regressor__n_neighbors': 19}   \n",
       "3                                                                                                                                              {'regressor__alpha': 1e-05}   \n",
       "4                                                                                                                                                  {'regressor__alpha': 1}   \n",
       "5                                                                                                            {'regressor__max_depth': 32, 'regressor__n_estimators': 1000}   \n",
       "6                                                                                {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}   \n",
       "7                                                                               {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}   \n",
       "8   {'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}   \n",
       "9                                                             {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "10                                                           {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "11                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "12                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "13                                             {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "0    0.023013  0.023359  \n",
       "1    0.021859  0.022136  \n",
       "2    0.013150  0.013031  \n",
       "3    0.012823  0.012928  \n",
       "4    0.012851  0.012933  \n",
       "5    0.012073  0.012055  \n",
       "6    0.007156  0.007156  \n",
       "7    0.007156  0.007166  \n",
       "8    0.012006  0.012018  \n",
       "9    0.005578  0.005553  \n",
       "10   0.005469  0.005436  \n",
       "11   0.004404  0.006614  \n",
       "12   0.002700  0.005142  \n",
       "13   0.003519  0.007485  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9be437d8-f4ee-4360-a5b0-b87dbe25de90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.005252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.005274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.005287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.005296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.005319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.005330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.005344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.005447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.005450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.005461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.005552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.005580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   parameters  \\\n",
       "4    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "20     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}   \n",
       "28    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "26     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "23    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "3    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}   \n",
       "1     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "21     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}   \n",
       "14  {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "33   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "11   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "24    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "10   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}   \n",
       "9    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}   \n",
       "8    {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}   \n",
       "30    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 2}   \n",
       "0     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 2}   \n",
       "19  {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 32}   \n",
       "27     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "7     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}   \n",
       "6     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}   \n",
       "25     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "38   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 16}   \n",
       "17   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 256, 'units layer 2': 8}   \n",
       "22     {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "34   {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}   \n",
       "5     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 2}   \n",
       "32    {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "12   {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}   \n",
       "2     {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "4    0.002700  0.005142  \n",
       "20   0.002566  0.005204  \n",
       "28   0.002482  0.005252  \n",
       "26   0.002381  0.005253  \n",
       "23   0.002779  0.005254  \n",
       "3    0.002425  0.005274  \n",
       "1    0.003137  0.005287  \n",
       "21   0.002550  0.005296  \n",
       "14   0.002182  0.005303  \n",
       "33   0.002448  0.005319  \n",
       "11   0.002470  0.005322  \n",
       "24   0.002298  0.005330  \n",
       "10   0.002163  0.005342  \n",
       "9    0.002383  0.005344  \n",
       "8    0.002328  0.005348  \n",
       "30   0.002080  0.005359  \n",
       "0    0.002853  0.005382  \n",
       "19   0.002489  0.005401  \n",
       "27   0.002436  0.005405  \n",
       "7    0.001993  0.005410  \n",
       "6    0.002396  0.005415  \n",
       "25   0.002201  0.005435  \n",
       "38   0.002083  0.005442  \n",
       "17   0.002561  0.005447  \n",
       "22   0.002421  0.005450  \n",
       "34   0.001984  0.005461  \n",
       "5    0.002495  0.005552  \n",
       "32   0.002321  0.005575  \n",
       "12   0.002283  0.005580  \n",
       "2    0.002557  0.005584  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results_df.sort_values(by = 'test_MSE', ascending = True).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c7d5739-aa79-461b-9790-16bd1973e389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2_results_df.to_csv(\"model_2_results_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89aed6bd-1338-40a6-a71d-9a1114d6ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2_params = model_2_results_df.loc[model_2_results_df.test_MSE == min(model_2_results_df.test_MSE), 'parameters'].values[0]\n",
    "model_2_train_MSE = model_2_results_df.loc[model_2_results_df.test_MSE == min(model_2_results_df.test_MSE), 'train_MSE'].values[0]\n",
    "model_2_test_MSE = model_2_results_df.loc[model_2_results_df.test_MSE == min(model_2_results_df.test_MSE), 'test_MSE'].values[0]\n",
    "\n",
    "results_df_full.loc[len(results_df_full.index)] = ('Embedding without pre-train', categorical_cols + numerical_cols + ['description'], \\\n",
    "                                                    model_2_params, model_2_train_MSE, model_2_test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b86733a-f511-46dc-b070-b51fec257b01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>variables</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.023013</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simple mean</td>\n",
       "      <td>['country mean_points']</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__n_neighbors': 19}</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.013031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR Lasso (L1)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1e-05}</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR Ridge (L2)</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__alpha': 1}</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 1000}</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.012055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NLP Bag of Words + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NLP TFIDF + LR</td>\n",
       "      <td>description</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>['description']</td>\n",
       "      <td>{'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.012018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All variables (NLP Bag of Words) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.005553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All variables (NLP TFIDF) + LR</td>\n",
       "      <td>['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']</td>\n",
       "      <td>{'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Embedding without pre-train</td>\n",
       "      <td>[country, province, region_1, variety, winery, year, price_log, description]</td>\n",
       "      <td>{'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Embedding with GloVe pre-train embbedings</td>\n",
       "      <td>[country, province, region_1, variety, winery, year, price_log, description]</td>\n",
       "      <td>{'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.007485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       method  \\\n",
       "0                                 simple mean   \n",
       "1                                 simple mean   \n",
       "2                                         KNN   \n",
       "3                               LR Lasso (L1)   \n",
       "4                               LR Ridge (L2)   \n",
       "5                               Random Forest   \n",
       "6                       NLP Bag of Words + LR   \n",
       "7                              NLP TFIDF + LR   \n",
       "8                               Random Forest   \n",
       "9       All variables (NLP Bag of Words) + LR   \n",
       "10             All variables (NLP TFIDF) + LR   \n",
       "11                Embedding without pre-train   \n",
       "12                Embedding without pre-train   \n",
       "13  Embedding with GloVe pre-train embbedings   \n",
       "\n",
       "                                                                                       variables  \\\n",
       "0                                                                                ['mean_points']   \n",
       "1                                                                        ['country mean_points']   \n",
       "2                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "3                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "4                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "5                  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year']   \n",
       "6                                                                                    description   \n",
       "7                                                                                    description   \n",
       "8                                                                                ['description']   \n",
       "9   ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "10  ['price_log', 'country', 'province', 'region_1', 'variety', 'winery', 'year', 'description']   \n",
       "11                                                                                 [description]   \n",
       "12                  [country, province, region_1, variety, winery, year, price_log, description]   \n",
       "13                  [country, province, region_1, variety, winery, year, price_log, description]   \n",
       "\n",
       "                                                                                                                                                                parameters  \\\n",
       "0                                                                                                                                                                       {}   \n",
       "1                                                                                                                                                                       {}   \n",
       "2                                                                                                                                           {'regressor__n_neighbors': 19}   \n",
       "3                                                                                                                                              {'regressor__alpha': 1e-05}   \n",
       "4                                                                                                                                                  {'regressor__alpha': 1}   \n",
       "5                                                                                                            {'regressor__max_depth': 32, 'regressor__n_estimators': 1000}   \n",
       "6                                                                                {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'vectorizer__max_features': None}   \n",
       "7                                                                               {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'vectorizer__max_features': 5000}   \n",
       "8   {'regressor__max_depth': 32, 'regressor__n_estimators': 500, 'vectorizer': TfidfVectorizer(max_features=5000, stop_words='english'), 'vectorizer__max_features': 5000}   \n",
       "9                                                             {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 10, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "10                                                           {'regressor': Ridge(alpha=0.1), 'regressor__alpha': 0.1, 'transformer__text__vectorizer__max_features': 5000}   \n",
       "11                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}   \n",
       "12                                                                {'desc_words': 5000, 'desc_len': 135, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}   \n",
       "13                                             {'desc_words': 5000, 'trainable': True, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}   \n",
       "\n",
       "    train_MSE  test_MSE  \n",
       "0    0.023013  0.023359  \n",
       "1    0.021859  0.022136  \n",
       "2    0.013150  0.013031  \n",
       "3    0.012823  0.012928  \n",
       "4    0.012851  0.012933  \n",
       "5    0.012073  0.012055  \n",
       "6    0.007156  0.007156  \n",
       "7    0.007156  0.007166  \n",
       "8    0.012006  0.012018  \n",
       "9    0.005578  0.005553  \n",
       "10   0.005469  0.005436  \n",
       "11   0.004404  0.006614  \n",
       "12   0.002700  0.005142  \n",
       "13   0.003519  0.007485  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7a07535d-fb50-497c-bdce-bb0171815b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_full.to_csv(\"results_df_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d93322-83aa-425e-8cb1-2ae32fd80c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml_2023",
   "language": "python",
   "name": "python_ml_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
